{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_file = './data/bobsue.voc.txt'\n",
    "train_file = './data/bobsue.lm.train.txt'\n",
    "test_file = './data/bobsue.lm.test.txt'\n",
    "dev_file = './data/bobsue.lm.dev.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从文件构建词汇集合并构建word2idx 与idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_set(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        word_set = set([line.strip() for line in f])\n",
    "    return word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = load_word_set(word_file)\n",
    "word2idx = {w:i for i, w in enumerate(word_set, 1)}\n",
    "idx2word = {i:w for i, w in enumerate(word_set, 1)}\n",
    "PAD_IDX = 0\n",
    "word2idx[\"<pad>\"] = PAD_IDX\n",
    "idx2word[PAD_IDX] = \"<pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练验证测试数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(filename):\n",
    "    \"\"\"读取数据集，返回句子列表\"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = [line.strip() for line in f]\n",
    "    return sentences\n",
    "\n",
    "def sentences2words(sentences):\n",
    "    return [w for s in sentences for w in s.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = load_corpus(train_file)\n",
    "dev_sentences = load_corpus(dev_file)\n",
    "test_sentences = load_corpus(test_file)\n",
    "\n",
    "train_words = sentences2words(train_sentences)\n",
    "dev_words = sentences2words(dev_sentences)\n",
    "test_words = sentences2words(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集句子数: 6036，单词数: 71367.\n",
      "验证集句子数: 750，单词数: 8707.\n",
      "测试集句子数: 750，单词数: 8809.\n"
     ]
    }
   ],
   "source": [
    "s = \"{}句子数: {}，单词数: {}.\"\n",
    "print(s.format(\"训练集\", len(train_sentences), len(train_words)))\n",
    "print(s.format(\"验证集\", len(dev_sentences), len(dev_words)))\n",
    "print(s.format(\"测试集\", len(test_sentences), len(test_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sentence_num(sentences):\n",
    "    \"\"\"返回最长句子单词数量\"\"\"\n",
    "    return max([len(s.split()) for s in sentences ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集最长句子单词个数： 21\n",
      "验证集最长句子单词个数： 20\n",
      "测试集最长句子单词个数： 21\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集最长句子单词个数：\", max_sentence_num(train_sentences))\n",
    "print(\"验证集最长句子单词个数：\", max_sentence_num(dev_sentences))\n",
    "print(\"测试集最长句子单词个数：\", max_sentence_num(test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sequence(corpus, word2idx, seq_len=21):\n",
    "    \"\"\"语料句子转换成模型输入的序列idx\"\"\"\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    for sentence in corpus:\n",
    "        words = sentence.split()\n",
    "        sentence_vec = [0]*seq_len\n",
    "        for i, w in enumerate(words[:-1]):\n",
    "            sentence_vec[i] = word2idx[w]\n",
    "        sentences.append(sentence_vec)\n",
    "        label_vec = [0] * seq_len\n",
    "        for i, w in enumerate(words[1:]):\n",
    "            label_vec[i] = word2idx[w]\n",
    "        labels.append(label_vec)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label = model_sequence(train_sentences, word2idx)\n",
    "dev_data, dev_label = model_sequence(dev_sentences, word2idx)\n",
    "test_data, test_label = model_sequence(test_sentences, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[237, 1094, 1044, 1471, 362, 15, 400, 900, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [1094, 1044, 1471, 362, 15, 400, 900, 1140, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[1], train_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> The girl broke up with Bob . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "\n",
      "The girl broke up with Bob . </s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> "
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "for i in train_data[idx]:\n",
    "    print(idx2word[i],  end=' ')\n",
    "print('\\n')\n",
    "for i in train_label[idx]:\n",
    "    print(idx2word[i], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_data\n",
    "def gen_batch_data(data, label, batch_size=32):\n",
    "    \"\"\"构建 batch tensor，返回 batch 列表，每个batch为二元组包含data和label\"\"\"\n",
    "    batch_data = []\n",
    "    data_tensor = torch.tensor(data, dtype=torch.long)\n",
    "    label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "    n, dim = data_tensor.size()\n",
    "    for start in range(0, n, batch_size):\n",
    "        end = start + batch_size\n",
    "        if end > n:\n",
    "            break\n",
    "        else:\n",
    "            dbatch = data_tensor[start: end]\n",
    "            lbatch = label_tensor[start: end]\n",
    "        batch_data.append((dbatch, lbatch))\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_batch = gen_batch_data(train_data, train_label, batch_size=BATCH_SIZE)\n",
    "dev_batch = gen_batch_data(dev_data, dev_label, batch_size=BATCH_SIZE)\n",
    "test_batch = gen_batch_data(test_data, test_label, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 23 23\n"
     ]
    }
   ],
   "source": [
    "print(len(train_batch), len(dev_batch), len(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(mylstm, self).__init__()\n",
    "        self.n_word = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(self.n_word, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.hidden2word = nn.Linear(hidden_dim, self.n_word)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embeds = self.word_embeddings(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embeds)\n",
    "        target_space = self.hidden2word(lstm_out.contiguous().view(-1, self.hidden_dim))\n",
    "        mask = (x != PAD_IDX).view(-1)\n",
    "        pure_target = target_space[mask]\n",
    "        \n",
    "        target_scores = F.log_softmax(pure_target, dim=1)\n",
    "        return target_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(word2idx)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 200\n",
    "\n",
    "model = mylstm(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model, device_ids=[0,1,2,3])\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_score(y_hat, y):\n",
    "    pred = y_hat.argmax(dim=1)\n",
    "#     print(y.view(-1))\n",
    "    acc_count = torch.eq(pred, y.view(-1))\n",
    "    score = acc_count.sum().item() / acc_count.size()[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, iterator, optimizer, criterion, grad_clip):\n",
    "    epoch_loss=0  # 积累变量\n",
    "    epoch_acc=0   # 积累变量\n",
    "    model.train() # 该函数表示PHASE=Train\n",
    "    \n",
    "    for x, y in iterator:  # 拿每一个minibatch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        mask = y != PAD_IDX\n",
    "        pure_y = y[mask]\n",
    "        \n",
    "        # 进行forward\n",
    "        fx = model(x)  \n",
    "        # 计算loss\n",
    "        loss = criterion(fx, pure_y)  \n",
    "        # 计算准确率\n",
    "        acc = acc_score(fx, pure_y) \n",
    "        # 进行BP\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        # 更新参数\n",
    "        optimizer.step() \n",
    "        \n",
    "        epoch_loss += loss\n",
    "        epoch_acc += acc\n",
    "    print(len(iterator))\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, iterator, criterion):\n",
    "    model.eval()  # 不更新参数，预测模式\n",
    "    epoch_loss=0  # 积累变量\n",
    "    epoch_acc=0   # 积累变量\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            mask = y != PAD_IDX\n",
    "            pure_y = y[mask]\n",
    "            \n",
    "            fx = model(x)\n",
    "            loss = criterion(fx, pure_y)\n",
    "            acc = acc_score(fx, pure_y)\n",
    "            epoch_loss += loss\n",
    "            epoch_acc += acc\n",
    "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:179: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "Epoch:1|Train Loss:1.9092416763305664|Train Acc:0.5186130259426801|Val Loss:4.2120184898376465|Val Acc:0.3113688752733935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type mylstm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "GRAD_CLIP = 5.\n",
    "EPOCHS = 1\n",
    "BEST_VALID_LOSS = float('inf')\n",
    "MODEL_PATH = \"lm-best.th\"\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    train_loss, train_acc = train(model, device, train_batch, optimizer, criterion, GRAD_CLIP)\n",
    "    valid_loss, valid_acc = evaluate(model, device, dev_batch, criterion)\n",
    "    if valid_loss < BEST_VALID_LOSS: # 如果是最好的模型就保存到文件夹\n",
    "        BEST_VALID_LOSS = valid_loss\n",
    "        torch.save(model, MODEL_PATH)\n",
    "        scheduler.step()\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.213463306427002 | Test Acc: 0.305538647283556 |\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(MODEL_PATH)\n",
    "test_loss, test_acc = evaluate(model, device, test_batch, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 打印错误单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_error_words(model, data_batch):\n",
    "    model.eval()\n",
    "    error_words = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_batch:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            mask = (y!=PAD_IDX)\n",
    "            fx = model(x)\n",
    "            \n",
    "            pred_idx = fx.argmax(dim=1)\n",
    "            ground_truth_idx = y[mask]\n",
    "            for p, g in zip(pred_idx.tolist(), ground_truth_idx.tolist()):\n",
    "                if p != g:\n",
    "                    error_words.append(\"#\".join([idx2word[g], idx2word[p]]))\n",
    "    return error_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py:179: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.dropout, self.training, self.bidirectional, self.batch_first)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(MODEL_PATH)\n",
    "error_words = print_pred_error_words(model, test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bob#He', 137)\n",
      "('She#He', 109)\n",
      "('Sue#He', 89)\n",
      "('had#was', 38)\n",
      "('to#.', 33)\n",
      "('decided#was', 33)\n",
      "('and#.', 32)\n",
      "('her#the', 32)\n",
      "('.#to', 27)\n",
      "('His#He', 26)\n",
      "('One#He', 25)\n",
      "('his#the', 23)\n",
      "('her#a', 22)\n",
      "('But#He', 21)\n",
      "('Her#He', 21)\n",
      "('The#He', 21)\n",
      "('for#.', 20)\n",
      "('When#He', 19)\n",
      "('the#his', 19)\n",
      "('They#He', 19)\n",
      "('she#he', 18)\n",
      "('the#her', 18)\n",
      "('went#was', 18)\n",
      "('got#was', 17)\n",
      "('a#the', 16)\n",
      "(',#.', 15)\n",
      "('the#.', 15)\n",
      "('wanted#was', 15)\n",
      "('!#.', 14)\n",
      "('.#the', 14)\n",
      "('he#to', 14)\n",
      "('It#He', 13)\n",
      "('the#a', 13)\n",
      "('in#.', 13)\n",
      "(\"'s#was\", 12)\n"
     ]
    }
   ],
   "source": [
    "words_counter = Counter(error_words)\n",
    "TopN = 35\n",
    "topn_words = words_counter.most_common(TopN)\n",
    "for w in topn_words:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
