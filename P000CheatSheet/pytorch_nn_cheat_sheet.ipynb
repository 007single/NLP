{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Embedding介绍\n",
    "- [https://pytorch.org/docs/stable/nn.html](https://pytorch.org/docs/stable/nn.html)\n",
    "----\n",
    "- pytorch里面实现word embedding是通过一个函数来实现的:nn.Embedding。Embedding的作用就是将词语向量化，通常会将词语表示为一个连续箱梁。\n",
    "- 官方介绍\n",
    "    - 一个简单的查找表，用于存储固定字典和大小的嵌入。\n",
    "    - 此模块通常用于存储单词嵌入并使用索引检索它们。模块的输入是索引列表，输出是相应的字嵌入。\n",
    "    \n",
    "- CLASS torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False, _weight=None)\n",
    "\n",
    "- 参数：\n",
    "    - num_embeddings (int) – 词典的大小，也就是词典有多少个词。比如你有一个30000的词典，这里就是30000.\n",
    "\n",
    "    - embedding_dim (int) – the size of each embedding vector。将词语表示成embedding_dim维的向量。指定向量的维度。\n",
    "\n",
    "    - padding_idx (int, optional) – If given, pads the output with the embedding vector at padding_idx (initialized to zeros) whenever it encounters the index.设置padding_idx后，padding_idx中的嵌入向量将初始化为全零。但是，请注意，之后可以修改该向量，例如，使用定制的初始化方法，从而改变用于填充输出的向量。嵌入中此向量的渐变始终为零。\n",
    "\n",
    "    - max_norm (float, optional) – If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm.\n",
    "    - norm_type (float, optional) – The p of the p-norm to compute for the max_norm option. Default 2.\n",
    "    - scale_grad_by_freq (boolean, optional) – If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default False.\n",
    "    - sparse (bool, optional) – If True, gradient w.r.t. weight matrix will be a sparse tensor. See Notes for more details regarding sparse gradients.\n",
    "- 看个例子吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5467,  0.0368,  0.5616, -0.4377, -1.5678]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 定义一个词典：word2idx = {'hello': 0, 'world': 1, '!':2}，每个单词我们需要用一个数字去表示它，这里对于hello这个词，用0来表示它。\n",
    "word2idx = {'hello': 0, 'world': 1, '!':2}\n",
    "\n",
    "# 定义Embedding层，这里的3表示词典共有3个词，5表示5维度，其实也就是一个3x5的矩阵.\n",
    "# 如果你有1000个词，每个词希望是100维，你就可以这样建立一个word embedding，nn.Embedding(1000, 100)。\n",
    "# 这就相当于词语和表示词语的向量建立了一张表，想知道一个词的向量表示可以通过这张表去查。\n",
    "embeds = nn.Embedding(3, 5)\n",
    "\n",
    "# 如何查询hello这个词的向量表示呢？\n",
    "\n",
    "# 通过词语在原来字典中的索引查词向量，hello的索引是0\n",
    "hello_idx = torch.LongTensor([word2idx['hello']])\n",
    "\n",
    "# 特别注意这里需要一个Variable，因为我们需要访问nn.Embedding里面定义的元素，且word embeding算是神经网络里面的参数，所以我们需要定义Variable\n",
    "hello_idx = Variable(hello_idx)\n",
    "# 现在输入Variable格式的索引就可以查看词向量了\n",
    "hello_embed = embeds(hello_idx)\n",
    "\n",
    "# 输出hello这个词的<初始词向量>\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意\n",
    "- 注意这里的词向量的建立只是**初始的词向量**，并没有经过任何修改优化，我们需要建立神经网络通过learning修改word embedding里面的参数使得word embedding每一个词向量能够表示每一个不同的词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(10, 20)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(5, 3, 10)  # seq_len, batch, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0176e+00,  2.1074e+00,  1.0802e+00,  1.6588e+00, -3.0665e-01,\n",
       "          -1.8412e-01, -1.1473e+00, -1.1237e+00, -8.2876e-02, -5.1729e-01],\n",
       "         [ 6.3862e-01,  1.1659e-01, -9.6650e-02, -1.1714e+00,  1.4072e-01,\n",
       "          -1.4833e+00, -2.3820e-01,  1.1966e+00,  4.0544e-01,  1.5256e-01],\n",
       "         [-1.5074e-01, -2.1995e+00, -8.5176e-01, -2.5534e+00,  4.7603e-01,\n",
       "          -6.3260e-01, -5.6957e-01,  1.4899e-02, -1.1266e+00,  1.2446e+00]],\n",
       "\n",
       "        [[ 1.7352e-03, -5.7774e-01, -6.1097e-01, -1.8013e-02, -1.3437e+00,\n",
       "           9.2696e-01,  1.9702e+00, -4.6417e-01, -1.8800e+00, -1.9298e-01],\n",
       "         [-9.0322e-02, -9.4674e-01, -5.4999e-01, -1.7946e+00, -8.9853e-01,\n",
       "          -1.0969e+00,  1.5586e+00,  1.6646e+00, -2.8987e-01, -1.5016e+00],\n",
       "         [-4.1151e-01, -7.2954e-04,  2.2337e-01, -9.8386e-01,  4.4936e-01,\n",
       "           9.2989e-01, -6.5802e-01,  1.5812e+00, -1.0958e+00, -6.1788e-02]],\n",
       "\n",
       "        [[-1.4971e+00,  3.9179e-01,  5.6520e-01, -6.3076e-01,  1.5079e-01,\n",
       "           3.3222e-01, -8.7468e-02,  4.5452e-01,  7.8680e-01, -1.5455e+00],\n",
       "         [-1.2999e+00, -5.6192e-01, -4.7842e-01, -1.6534e+00,  5.5870e-01,\n",
       "          -1.2644e+00, -9.4834e-01,  1.0010e-01,  4.2872e-01,  5.3252e-02],\n",
       "         [ 1.4527e+00, -4.3388e-01, -3.3498e-01, -1.0030e+00,  1.1013e+00,\n",
       "          -3.4910e-01,  6.8456e-01,  2.6043e-01,  4.1759e-01,  1.3610e-01]],\n",
       "\n",
       "        [[ 1.3875e+00, -4.4216e-01, -1.0263e+00, -1.1043e+00, -8.0397e-01,\n",
       "           8.0906e-02, -6.3133e-01,  1.1658e+00,  4.3143e-01, -1.1788e+00],\n",
       "         [-2.8972e+00,  3.5283e-01, -4.4820e-01,  1.2151e-02,  2.3741e+00,\n",
       "           2.0222e-01,  2.6888e+00,  1.1056e-02, -7.0525e-01, -1.0253e-01],\n",
       "         [-2.1252e+00, -1.5149e-01, -3.5398e-02, -8.3259e-02,  1.3254e+00,\n",
       "          -3.0418e-02, -1.1798e+00, -5.6412e-01, -1.2949e+00,  1.0080e+00]],\n",
       "\n",
       "        [[-6.7079e-01,  4.8174e-02,  1.0707e+00, -5.4776e-01,  5.8097e-01,\n",
       "          -1.2893e+00,  3.3954e-01,  4.8084e-01,  1.8950e-02, -2.2505e+00],\n",
       "         [ 2.3165e+00, -7.6931e-01,  9.4698e-02,  6.8391e-01,  9.6858e-01,\n",
       "          -7.4724e-02,  1.1246e+00, -4.3779e-02,  2.6507e-01, -6.3653e-01],\n",
       "         [-1.5829e+00,  1.1478e+00,  6.8237e-02,  1.5827e+00,  3.3815e-02,\n",
       "          -1.2804e+00,  6.5212e-01, -9.5279e-01,  1.7082e-01,  1.9955e+00]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h0 = torch.randn(1, 3, 20)\n",
    "# h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c0 = torch.randn(1, 3, 20)\n",
    "# c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = rnn(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0705,  0.0806, -0.0004,  0.1699, -0.0639,  0.2456,  0.1708, -0.0649,\n",
       "         0.0175, -0.1028,  0.0625, -0.2196, -0.0772,  0.1272,  0.2425, -0.0047,\n",
       "        -0.1266, -0.1277,  0.1271, -0.1731], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0397, -0.1044, -0.3107,  0.1052, -0.0923,  0.2201,  0.2007, -0.1051,\n",
       "         0.2590, -0.0161, -0.0058, -0.0728, -0.0446,  0.1594, -0.0887, -0.1233,\n",
       "         0.0534,  0.2600, -0.2403, -0.2578], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn2 = nn.LSTM(10, 20, batch_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bacth,seq_len, word_vec_dim\n",
    "input_data2 = torch.randn(32, 5, 10)  # hc层size(layer_num, bacth, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (hn, cn) = rnn2(input_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5, 20]) torch.Size([1, 32, 20]) torch.Size([1, 32, 20])\n"
     ]
    }
   ],
   "source": [
    "print(out.size(), hn.size(), cn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(2).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5343,  1.1623]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两个形状相同的tonsor相乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3], \n",
    "                  [2,3,4]])\n",
    "b = torch.tensor([[2,2,2], \n",
    "                  [2,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4, 6],\n",
       "        [4, 6, 4]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a*b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3521,  0.3300,  1.8152,  0.2920, -0.3818,  1.3390, -0.6421,\n",
       "          -0.5181, -0.6548, -1.3408],\n",
       "         [-1.4215,  1.0278, -0.3704,  1.1732,  0.5826, -1.0977, -0.1229,\n",
       "           0.7543,  0.1068, -0.9253],\n",
       "         [ 0.2701, -0.0540,  0.5477,  1.9520,  1.1553,  2.0301, -1.3622,\n",
       "           0.6728,  1.1550, -0.5492],\n",
       "         [-0.9010,  0.9355, -1.2293, -0.6187, -0.3745,  1.3888, -0.1698,\n",
       "           1.5389,  0.2122,  0.3061],\n",
       "         [-0.8861, -0.2416,  0.1654, -0.4934, -0.3101, -0.0811,  1.3597,\n",
       "          -1.3795,  0.5985,  1.5860]],\n",
       "\n",
       "        [[ 0.9069,  0.8176, -1.4616, -1.4370,  1.6841,  0.0073,  2.1817,\n",
       "          -0.2038,  0.0430,  0.4026],\n",
       "         [ 0.4725,  1.8585, -0.1899, -1.5201, -1.4479,  1.2178, -2.5778,\n",
       "          -0.9094,  0.6352,  1.1748],\n",
       "         [-1.1253,  0.7802,  0.1728,  1.6081, -0.3923, -2.0803,  0.3759,\n",
       "          -0.8075,  1.2691, -0.1470],\n",
       "         [ 0.3799, -1.0446,  1.4070,  0.6546, -0.2464,  0.8234,  1.1070,\n",
       "          -0.3188, -0.4323,  1.3733],\n",
       "         [-0.1135,  0.0418,  0.2190,  0.6118,  0.5848, -0.2570, -0.9862,\n",
       "          -0.5180,  0.7181, -0.6088]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2, 5, 10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.sum(2)\n",
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0955, -0.0487,  1.8012, -0.2057, -0.9501],\n",
       "         [ 0.1482,  0.0884,  0.2197,  0.1176, -0.3785],\n",
       "         [-0.1032, -0.3398,  1.2709, -0.1059, -0.3674]],\n",
       "\n",
       "        [[-0.4318, -0.9047, -0.2204, -1.1353, -2.1245],\n",
       "         [ 1.2986,  1.5762, -0.6559,  0.8941,  0.4001],\n",
       "         [ 0.8741,  0.1495,  1.0028,  1.4448, -0.0584]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([2,3,5])\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [0, 0, 1, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 1, 1],\n",
       "         [1, 1, 1, 1, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (x>0)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0955, 1.8012, 0.1482, 0.0884, 0.2197, 0.1176, 1.2709, 1.2986, 1.5762,\n",
       "        0.8941, 0.4001, 0.8741, 0.1495, 1.0028, 1.4448])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = x[mask]    # 压扁成一个列表\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = F.logsigmoid(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3977)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean()   # 得到一个数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.2231)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(1 - torch.sigmoid(d)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
